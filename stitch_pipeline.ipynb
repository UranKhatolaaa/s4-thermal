{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "technical-drive",
   "metadata": {},
   "source": [
    "# Image processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "military-carter",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in /opt/conda/lib/python3.7/site-packages (0.5.4)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.5.3.56)\n",
      "Requirement already satisfied: simplekml in /opt/conda/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: palettable in /opt/conda/lib/python3.7/site-packages (3.3.0)\n",
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.7/site-packages (3.13.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.59.0)\n",
      "Requirement already satisfied: requests[socks]>=2.12.0 in /opt/conda/lib/python3.7/site-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.0.12)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (4.0.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python) (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "%pip install imutils opencv-python simplekml palettable gdown\n",
    "import gdown\n",
    "import os\n",
    "import glob\n",
    "import rasterio as ro\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Proj\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import griddata\n",
    "from PIL import Image\n",
    "from skimage.measure import block_reduce\n",
    "import cv2\n",
    "import imageio\n",
    "import imutils\n",
    "import helper_functions as hf\n",
    "from palettable import colorbrewer\n",
    "from scipy import ndimage\n",
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eight-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "gdrive = False # Download data from google drive\n",
    "link = 'https://drive.google.com/file/d/1ANJ_Hq3C42Zfka_wIDX7wgbH_hwcUbGn/view?usp=sharing' # gdrive link\n",
    "imgDir = 'data/120' # Local directory to images\n",
    "imageType, cmap = False, colorbrewer.get_map('RdYlBu', 'diverging', 11, reverse=True).mpl_colormap # True if RGB images, False if numpy arrays. Choose matplotlib cmap for thermal\n",
    "pathFile = 'data/lsm/Flight 1.csv' # Flight path .csv file\n",
    "utcDiff = -1 # Time difference to UTC (-1 for BST)\n",
    "pathColumns = ['timestamp','latitude','longitude','altitude(m)','pitch(deg)','roll(deg)','yaw(deg)'] # Columns used from the path file\n",
    "minAlt, maxAlt, altCol = 119.7, 120.3, 'altitude(m)' # Altitude criteria for using imagery, if wanted else False\n",
    "imgTimes = False#[1619811011923,1619811099149] # Specify times if wanted else False\n",
    "utmZone, hemisphere = '31n', 'north' # Specify UTM coordinate zone\n",
    "pxSize = 0.27 # Specify pixel size (m) - for now\n",
    "resolution = 6 # Other resolution for plots\n",
    "useCentre = True # True if only using center of images\n",
    "skip = 20 # Plot every nth image for path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "progressive-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download from google drive if gdrive is True\n",
    "#%capture\n",
    "if gdrive: \n",
    "    zippath = imgDir+'.zip'\n",
    "    downLink = link.split('/d/')[1].split('/view')[0]\n",
    "    ! gdown -O $zippath 'https://drive.google.com/uc?export=download&id='$downLink\n",
    "    ! unzip $zippath -d $imgDir\n",
    "    ! rm $zippath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get image dataframe with corresponding properties extracted frpm path file\n",
    "fileTypes = ('.jpg','.png','.tif') if imageType else ('.npy')\n",
    "imgs = [_ for _ in glob.glob(imgDir+'*.*') if _.endswith(fileTypes)]\n",
    "imgs.sort()\n",
    "# Extract date and time from filenames\n",
    "imgdates = [re.search('/20(.+?)_', path).group(1) for path in imgs] # Extract date from filename\n",
    "imgtimes = [re.search('_(.+?)_', path).group(1) for path in imgs] # Extract time from filename\n",
    "# Convert to unix datetime \n",
    "imgdatetimes = np.array([(datetime.timestamp(datetime(int('20'+imgdates[i][:2]),int(imgdates[i][2:4]),int(imgdates[i][4:6]),int(imgtimes[i][:2])+utcDiff,int(imgtimes[i][2:4]),int(imgtimes[i][4:6])))) for i in range(len(imgs))])*1000\n",
    "\n",
    "# Imprt paths and get corresponding timestamps for images\n",
    "pathDf = pd.read_csv(pathFile)\n",
    "# Get nearest GPS timestamp\n",
    "gpstimes = [min(pathDf['timestamp'], key=(lambda list_value : abs(list_value - i))) for i in imgdatetimes]\n",
    "\n",
    "# Create image dataframe\n",
    "imgDf = pd.DataFrame(data=np.array([imgs,gpstimes]).transpose(),columns=['imgPath','timestamp'])\n",
    "imgDf['timestamp'] = imgDf['timestamp'].astype(float)\n",
    "\n",
    "# Merge with path dataframe\n",
    "merged = imgDf.merge(pathDf[pathColumns], on='timestamp', how='left')\n",
    "# Filter for acceptable measurement altitudes\n",
    "merged = merged.loc[(merged[altCol] > minAlt) & (merged[altCol] < maxAlt)]\n",
    "if imgTimes: merged = merged.loc[(merged['timestamp'] > imgTimes[0]) & (merged['timestamp'] < imgTimes[1])]\n",
    "\n",
    "# Convert coordinates to UTM\n",
    "myProj = Proj('+proj=utm +zone='+utmZone+', +'+hemisphere+' +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n",
    "merged['x'], merged['y'] = myProj(merged['longitude'].values, merged['latitude'].values)\n",
    "\n",
    "# Display example\n",
    "merged.head()\n",
    "\n",
    "distFilt = 6 # Filter out images where angle is high\n",
    "\n",
    "fig, axs = plt.subplots(2,2,figsize=[11,8])\n",
    "# Pitch/roll/yaw plot\n",
    "axs[0,0].plot(merged.index,merged['pitch(deg)'],label='pitch')\n",
    "axs[0,0].plot(merged.index,merged['roll(deg)'],label='roll')\n",
    "par1 = ax.twinx()\n",
    "par1.plot(merged.index,merged['yaw(deg)'],c='g',label='yaw')\n",
    "ax.set_title(' Pitch/roll/yaw evolution')\n",
    "ax.set_xlabel('Image number'), ax.set_ylabel('Degrees (pitch & roll)')\n",
    "par1.set_ylabel('Degrees (yaw)')\n",
    "fig.legend(loc='upper left')\n",
    "\n",
    "# Coordinate corrections\n",
    "# Angle corrected\n",
    "dist = merged['altitude(m)']*np.tan(np.deg2rad(merged['pitch(deg)']))\n",
    "merged['xc'], merged['yc'] = merged.x+(dist*np.sin(np.deg2rad(merged['yaw(deg)']))), merged.y+(dist*np.cos(np.deg2rad(merged['yaw(deg)'])))\n",
    "if distFilt: idf = merged[abs(dist) < distFilt]\n",
    "else: idf = merged.copy()\n",
    "    \n",
    "## Plot flight path with an example image and downscale\n",
    "# Plot example image\n",
    "arr = hf.img_to_arr(merged.iloc[imageNum]['imgPath'])\n",
    "yCoords, xCoords = [(np.array(range(arr.shape[i]))-(arr.shape[i]/2))*pxSize+pxSize/2 for i in [0,1]]\n",
    "if useCentre: xq, yq = int(np.floor(len(xCoords)/4)), int(np.floor(len(yCoords)/4))\n",
    "else: xq, yq = False, False\n",
    "arr = hf.img_to_arr(merged.iloc[imageNum]['imgPath'], xq=xq, yq=yq)\n",
    "a = axs[1,0].imshow(arr, cmap=cmap)\n",
    "axs[1,0].set_title('Image {}'.format(imageNum))\n",
    "\n",
    "# Plot images to be used\n",
    "b = axs[0,1].scatter(idf.xc,idf.yc,c=idf.index, cmap='Spectral')\n",
    "size = np.array(arr.shape[:2])*pxSize/2\n",
    "for i, row in idf[::skip].iterrows():\n",
    "    axs[0,1].plot([row.x-size[1], row.x+size[1]], [row.y, row.y],'k-o')\n",
    "    axs[0,1].plot([row.x, row.x],[row.y-size[1], row.y+size[1]],'k-o')\n",
    "axs[0,1].set_title('Used image coordinates')\n",
    "axs[0,1].legend(labels=['Extent for every {}th'.format(skip)])\n",
    "fig.colorbar(b, ax=axs[0,1],label='Photo number')\n",
    "\n",
    "# Plot example downsampled image\n",
    "ds_array = hf.downsample_arr(arr, pxSize, resolution)\n",
    "c = axs[1,1].imshow(ds_array) if imageType else axs[1,i].imshow(ds_array, vmin=arr.min(), vmax=arr.max(),cmap=cmap)\n",
    "axs[1,1].set_title('Image {} downsampled to {} m resolution'.format(str(imageNum),resolution))\n",
    "if imageType is False: fig.colorbar(c, ax=axs[1,1], label=' Temperature ($^{\\circ}$C)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try xy if you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-image stitching\n",
    "if 'result' in globals(): del(result)\n",
    "# Setup variables\n",
    "start = 1\n",
    "end = 19\n",
    "step = 1\n",
    "skips = [17, 26,29,37,44,45,56]\n",
    "xmin, xmax, ymin, ymax = 0,0,0,0\n",
    "\n",
    "# Stitching properties\n",
    "feature_extractor = 'orb'\n",
    "feature_matching = 'bf'\n",
    "tempfiles = ['temp0.jpg','temp1.jpg']\n",
    "prev = start\n",
    "\n",
    "arr = hf.img_to_arr(idf.iloc[start]['imgPath'], xq=xq, yq=yq)\n",
    "single = ((arr+10)*255/40)\n",
    "imageio.imwrite(tempfiles[0],np.dstack((single,single,single)))\n",
    "prevImg = np.dstack((single,single,single)).astype(np.uint8)\n",
    "totalBox=[prevImg.shape[0], prevImg.shape[1]]\n",
    "prevBox=[0,prevImg.shape[0],0,prevImg.shape[1]]\n",
    "\n",
    "for imgNum in tqdm(np.arange(start+step if start < end else start-step,end+1,step if start < end else -step)):\n",
    "    if imgNum in skips:\n",
    "        continue\n",
    "    arrs = [hf.img_to_arr(idf.iloc[prev]['imgPath'], xq=xq, yq=yq),hf.img_to_arr(idf.iloc[imgNum]['imgPath'], xq=xq, yq=yq)]\n",
    "\n",
    "    for i, val in enumerate(tempfiles): \n",
    "        single = ((arrs[i]+10)*255/40)\n",
    "        imageio.imwrite(val,np.dstack((single,single,single)))\n",
    "    # Read images - Make sure that the train image is the image that will be transformed\n",
    "    trainImg, queryImg = [imageio.imread(i) for i in tempfiles]\n",
    "    #for i in tempfiles: os.remove(i)\n",
    "    # Opencv defines the color channel in the order BGR - transform it to RGB to be compatible to matplotlib\n",
    "    trainImg_gray, queryImg_gray = [cv2.cvtColor(i, cv2.COLOR_RGB2GRAY) for i in [trainImg, queryImg]]\n",
    "\n",
    "    # Detect the keypoints and features on both images\n",
    "    kpsA, featuresA = hf.detectAndDescribe(trainImg_gray, method=feature_extractor)\n",
    "    kpsB, featuresB = hf.detectAndDescribe(queryImg_gray, method=feature_extractor)\n",
    "\n",
    "    # Link  the identified features between images\n",
    "    if feature_matching == 'bf':\n",
    "        matches = hf.matchKeyPointsBF(featuresA, featuresB, method=feature_extractor)\n",
    "    elif feature_matching == 'knn':\n",
    "        matches = hf.matchKeyPointsKNN(featuresA, featuresB, ratio=0.75, method=feature_extractor)\n",
    "\n",
    "    # Potential to improve by filtering out matches that are not in same direction of travel as drone\n",
    "    ma = np.array([kpsA[j].pt for j in [i.queryIdx for i in matches]])\n",
    "    mb = np.array([kpsB[j].pt for j in [i.trainIdx for i in matches]])\n",
    "\n",
    "    # Filter by only matches in direction of travel\n",
    "    xmov, ymov = idf.iloc[imgNum]['xc']-idf.iloc[prev]['xc'], idf.iloc[imgNum]['yc']-idf.iloc[prev]['yc']\n",
    "    bothMov = 2\n",
    "    if abs(xmov) < bothMov/2 and abs(ymov) < bothMov/2:\n",
    "        mam, mbm = ma, mb\n",
    "    else: \n",
    "        if abs(xmov) > abs(ymov):\n",
    "            if xmov < 0:\n",
    "                mam, mbm = ma[[ma[i,0]>mb[i,0] for i in range(len(ma))]], mb[[ma[i,0]>mb[i,0] for i in range(len(ma))]]\n",
    "            else: mam, mbm = ma[[ma[i,0]>mb[i,0] for i in range(len(ma))]], mb[[ma[i,0]>mb[i,0] for i in range(len(ma))]]\n",
    "        else:\n",
    "            if ymov < 0:\n",
    "                mam, mbm = ma[[ma[i,1]<mb[i,1] for i in range(len(ma))]], mb[[ma[i,1]<mb[i,1] for i in range(len(ma))]]\n",
    "            else: mam, mbm = ma[[ma[i,1]>mb[i,1] for i in range(len(ma))]], mb[[ma[i,1]>mb[i,1] for i in range(len(ma))]]\n",
    "#     xmov, ymov = idf.iloc[imgNum]['yc']-idf.iloc[prev]['yc'], idf.iloc[imgNum]['xc']-idf.iloc[prev]['xc']\n",
    "#     bothMov = 2\n",
    "#     if abs(xmov) < bothMov/2 and abs(ymov) < bothMov/2:\n",
    "#         mam, mbm = ma, mb\n",
    "#     else: \n",
    "#         if abs(xmov) > abs(ymov):\n",
    "#             if xmov < 0:\n",
    "#                 #print('hello')\n",
    "#                 mam, mbm = ma[[ma[i,0]>mb[i,0] for i in range(len(ma))]], mb[[ma[i,0]>mb[i,0] for i in range(len(ma))]]\n",
    "#             else: \n",
    "#                 print('hello')\n",
    "#                 mam, mbm = ma[[ma[i,0]<mb[i,0] for i in range(len(ma))]], mb[[ma[i,0]<mb[i,0] for i in range(len(ma))]]\n",
    "#         else:\n",
    "#             if ymov < 0:\n",
    "#                 mam, mbm = ma[[ma[i,1]>mb[i,1] for i in range(len(ma))]], mb[[ma[i,1]>mb[i,1] for i in range(len(ma))]]\n",
    "#             else: mam, mbm = ma[[ma[i,1]<mb[i,1] for i in range(len(ma))]], mb[[ma[i,1]<mb[i,1] for i in range(len(ma))]]\n",
    "\n",
    "    # Difference between 2 images considered\n",
    "    diff = np.median(mam-mbm, axis=0).astype(int)\n",
    "  \n",
    "    #------------------#    \n",
    "    if len(mam) > 10 and np.std(mam-mbm, axis=0).mean() < 50:\n",
    "            # Work out new positions\n",
    "        newBox=[int(np.round(prevBox[0]+diff[1])), int(np.round(prevBox[1]+diff[1])), int(np.round(prevBox[2]+diff[0])),int(np.round(prevBox[3]+diff[0]))] # New box position before adjustment for expanding total box\n",
    "\n",
    "        pos = [0,0] # Position for previously merged images\n",
    "        modBox = [0,0,0,0] # Position for new image\n",
    "        # If bounds on axis 0 go beyond total\n",
    "        if newBox[0]<0:\n",
    "            xmin = imgNum\n",
    "            totalBox[0]+=abs(newBox[0])\n",
    "            modBox[1] = newBox[1]-newBox[0]\n",
    "            modBox[0] = 0\n",
    "            pos[0] = abs(newBox[0])\n",
    "        elif newBox[1] > totalBox[0]:\n",
    "            xmax=imgNum\n",
    "            totalBox[0]=newBox[1]\n",
    "            modBox[1] = newBox[1]\n",
    "            modBox[0] = newBox[0]\n",
    "            pos[0] = 0\n",
    "        else: modBox[0], modBox[1], pos[0] = newBox[0], newBox[1], 0\n",
    "        # If bounds on axis 1 go beyond total\n",
    "        if newBox[2]<0:\n",
    "            ymin=imgNum\n",
    "            totalBox[1]+=abs(newBox[2])\n",
    "            modBox[3] = newBox[3]-newBox[2]\n",
    "            modBox[2] = 0\n",
    "            pos[1] = abs(newBox[2])\n",
    "        elif newBox[3] > totalBox[1]:\n",
    "            ymax=imgNum\n",
    "            totalBox[1]=newBox[3]\n",
    "            modBox[3] = newBox[3]\n",
    "            modBox[2] = newBox[2]\n",
    "            pos[1] = 0\n",
    "        else: modBox[2], modBox[3], pos[1] = newBox[2], newBox[3], 0    \n",
    "        prevBox = modBox  \n",
    "        \n",
    "        single = (arrs[1]+10)*255/40\n",
    "        queryImg = np.dstack((single,single,single)).astype(np.uint8)\n",
    "        #queryImg = [np.dstack((((arrs[i]+10)*255/40),((arrs[i]+10)*255/40),((arrs[i]+10)*255/40))).astype(np.uint8) for i in range(len(imageNums))]\n",
    "        result = np.zeros([totalBox[0],totalBox[1],3])\n",
    "        result[pos[0]:pos[0]+prevImg.shape[0],pos[1]:pos[1]+prevImg.shape[1],:] = prevImg\n",
    "        result[modBox[0]:modBox[1], modBox[2]:modBox[3],:] = queryImg\n",
    "        print('Images {} and {} merged.'.format(str(prev),str(imgNum)))\n",
    "        prev=imgNum\n",
    "        prevImg = result\n",
    "    else: print('Images {} and {}, poor matching'.format(str(prev),str(imgNum)))\n",
    "    \n",
    "    \n",
    "fig = plt.figure(figsize=(20,10))\n",
    "#extent = (idf.iloc[imgNum]['xc']-img\n",
    "plt.imshow(result.mean(axis=2),cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as kmz\n",
    "inputCoords = True\n",
    "userInputCoords = np.array([[0.106680, 0.108845],[52.204120, 52.204950]])\n",
    "pixels = 1024 * 10\n",
    "cmap = colorbrewer.get_map('RdYlBu', 'diverging', 11, reverse=True).mpl_colormap\n",
    "if inputCoords: conv = userInputCoords\n",
    "else: conv = np.array(myProj([idf.iloc[xmin]['yc']-pxSize*(np.floor(queryImg.shape[0]/2)+0.5), idf.iloc[xmax]['yc']+pxSize*(np.floor(queryImg.shape[0]/2)+0.5)],\n",
    "                       [idf.iloc[ymin]['xc']-pxSize*(np.floor(queryImg.shape[1]/2)+0.5), idf.iloc[ymax]['xc']+pxSize*(np.floor(queryImg.shape[1]/2)+0.5)], inverse=True))\n",
    "fig, ax = hf.gearth_fig(llcrnrlon=conv[0].min(), llcrnrlat=conv[1].min(),\n",
    "                         urcrnrlon=conv[0].max(), urcrnrlat=conv[1].max(),\n",
    "                         pixels=pixels)\n",
    "\n",
    "rot = ndimage.rotate(result.mean(axis=2), 90)\n",
    "single = np.ma.masked_where(rot < 1e-1, rot)/255*40-10\n",
    "cs = ax.imshow(single,extent=(conv[0].min(),conv[0].max(),conv[1].min(),conv[1].max()), cmap=cmap, vmin=single.min(),vmax=single.max())\n",
    "ax.set_axis_off()\n",
    "fig.savefig('original0-25.png', transparent=True, format='png', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 6\n",
    "fig, ax = hf.gearth_fig(llcrnrlon=conv[0].min(), llcrnrlat=conv[1].min(),\n",
    "                         urcrnrlon=conv[0].max(), urcrnrlat=conv[1].max(),\n",
    "                         pixels=pixels)\n",
    "#ds = hf.downsample_arr(single,pxSize,resolution)\n",
    "#single = rot/255*50-10\n",
    "ds = np.ma.masked_where(abs(hf.downsample_arr(single.filled(),pxSize,resolution)) > 1e3, hf.downsample_arr(single,pxSize,resolution))\n",
    "cs = ax.imshow(ds,extent=(conv[0].min(),conv[0].max(),conv[1].min(),conv[1].max()), cmap=cmap, vmin=single.min(),vmax=single.max())\n",
    "ax.set_axis_off()\n",
    "fig.savefig('downsample0-25.png', transparent=True, format='png', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(1.0, 4.0))\n",
    "ax = fig.add_axes([0.07, 0.05, 0.27, 0.9])\n",
    "cb = fig.colorbar(cs, cax=ax)\n",
    "cb.set_label('Temperature ($^{\\circ}$C)', rotation=-90, color='k', labelpad=20, fontsize=13)\n",
    "fig.tight_layout()\n",
    "fig.savefig('legend.png', format='png', bbox_inches = 'tight', pad_inches = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flight Path\n",
    "stop = 25\n",
    "x, y = idf.longitude[:stop], idf.latitude[:stop]\n",
    "fig, ax = hf.gearth_fig(llcrnrlon=conv[0].min(), llcrnrlat=conv[1].min(),\n",
    "                         urcrnrlon=conv[0].max(), urcrnrlat=conv[1].max(),\n",
    "                         pixels=pixels)\n",
    "ax.plot(x,y,'k-',linewidth=2,label='raw')\n",
    "ax.set_axis_off()\n",
    "fig.savefig('path0-25.png', transparent=True, format='png', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.make_kml(llcrnrlon=conv[0].min(), llcrnrlat=conv[1].min(),\n",
    "         urcrnrlon=conv[0].max(), urcrnrlat=conv[1].max(),\n",
    "         figs=['overlay1.png', 'overlay2.png','path.png'], colorbar='legend.png',\n",
    "         kmzfile='stitch_thermal.kmz', description=str(resolution)+'m resolution thermal imagery', name='Satellite resolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as .csv file\n",
    "ds_arr = ds.shape\n",
    "ptslon = np.linspace(conv[0].min(),conv[0].max(),ds_arr[1]+1)[:-1]\n",
    "ptslon += (ptslon[1]-ptslon[0])/2\n",
    "ptslat = np.linspace(conv[1].min(),conv[1].max(),ds_arr[0]+1)[:-1]\n",
    "ptslat += (ptslat[1]-ptslat[0])/2\n",
    "lonm, latm = np.meshgrid(ptslon,ptslat)\n",
    "\n",
    "import pandas as pd\n",
    "ds_q = int(np.floor(resolution/pxSize))\n",
    "arr = np.round(single[:-(single.shape[0] % ds_q),:-(single.shape[1] % ds_q)]).astype(int)\n",
    "most=np.zeros([len(range(0,arr.shape[0]-ds_q,ds_q))+1, len(range(0,arr.shape[1]-ds_q,ds_q))+1])\n",
    "for i in range(0,arr.shape[0],ds_q):\n",
    "    for j in range(0,arr.shape[1],ds_q):\n",
    "        most[int(i/ds_q),int(j/ds_q)] = Counter(arr[i:i+ds_q,j:j+ds_q].reshape(1,-1).tolist()[0]).most_common(1)[0][0]\n",
    "        \n",
    "tdf = pd.DataFrame(np.concatenate([np.flip(latm.reshape(-1,1)), lonm.reshape(-1,1), ds.reshape(-1,1), most.reshape(-1,1)], axis=1), columns=['Latitude', 'Longitude', '6m T(C)', '0.27cm T(C)'])\n",
    "filt = tdf[ds.mask.reshape(-1,1) == False]\n",
    "filt.to_csv('plots/stitch_temps.csv', index_label='UID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
